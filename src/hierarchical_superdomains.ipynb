{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hierarchical algorithm to identify semi-rigid domains an super-domains in proteins\n",
    "Written by Mahtab.\n",
    "\n",
    "This script is the implementation of hierarchical algorithm to identify semi-rigid domains an super-domains in proteins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nessecary imports\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import cdist\n",
    "import MDAnalysis as mda\n",
    "from MDAnalysis.analysis import align, rms\n",
    "from typing import *\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import cm\n",
    "from collections import defaultdict\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from scipy.stats import norm\n",
    "import statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "topology_file = '/path/to/topology/file' \n",
    "trajectory_file = '/path/to/trajectory/file'     \n",
    "begin = 0   # the starting frame (The first frame of the trajectory we want to include in clustering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a Union-Find (or Disjoin-Set) class\n",
    "class UnionFind:\n",
    "    def __init__(self):\n",
    "        self.parent = {}\n",
    "    \n",
    "    # Function that finds the root of a node.\n",
    "    def find(self, x):\n",
    "        if self.parent[x] != x:\n",
    "            self.parent[x] = self.find(self.parent[x])\n",
    "        \n",
    "        return self.parent[x]\n",
    "    \n",
    "    # Function that joins the groups of x and y\n",
    "    def union(self, x, y):\n",
    "        root_x = self.find(x)\n",
    "        root_y = self.find(y)\n",
    "        if root_x != root_y:\n",
    "            self.parent[root_x] = root_y\n",
    "\n",
    "    # Function that adds x to the data structure if it wasn't before.\n",
    "    def add(self, x):\n",
    "        if x not in self.parent:\n",
    "            self.parent[x] = x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions.\n",
    "\n",
    "# Computes the S matrix (normalized standard deviation of distance variation) from the topology and trajectory files.\n",
    "def S_generator(topology_file: str, trajectory_file: str, selection: str = \"protein and name CA\") -> np.ndarray:\n",
    "\n",
    "    # Load the topology and trajectory files in to the universe \"u\"\n",
    "    u = mda.Universe(topology_file, trajectory_file)\n",
    "\n",
    "    # Get the coordinates of the atoms.\n",
    "    atoms = u.select_atoms(selection)\n",
    "    n_atoms = atoms.n_atoms\n",
    "    n_frames = len(u.trajectory[begin:])\n",
    "\n",
    "    print('\\nnumber of selected atoms: ', n_atoms)\n",
    "    print('\\nnumber of frames: ', n_frames)\n",
    "\n",
    "    # arrays for storing sum of pair distances and sum of squared pair distances\n",
    "    sum_pairDistances = np.zeros((n_atoms, n_atoms))\n",
    "    sum_squaredDistances = np.zeros((n_atoms, n_atoms))\n",
    "\n",
    "    # compute pairwise distances over each frame.\n",
    "    for f, ts in enumerate(u.trajectory[begin:]):\n",
    "       print(f\"\\n frame: {f}\")\n",
    "       # compute pairwise distances for frame f\n",
    "       distances = cdist(atoms.positions, atoms.positions, metric='euclidean') \n",
    "\n",
    "       # Accumulate the pairwise distances and squeared pairwise distances\n",
    "       sum_pairDistances += distances\n",
    "       sum_squaredDistances += distances ** 2\n",
    "    \n",
    "    # compute average of pairwise distance over the trajectory\n",
    "    average_pairDistances = sum_pairDistances / n_frames\n",
    "\n",
    "    # compute the average of squared pairwise distances over the trajectory\n",
    "    average_squaredDistances = sum_squaredDistances / n_frames\n",
    "\n",
    "    # compute variance (squared distance variations)\n",
    "    variance = average_squaredDistances - average_pairDistances ** 2\n",
    "\n",
    "    # Caluculate standard deviation (STDDV) matrix shape(n_atoms * n_atoms).\n",
    "    S = np.sqrt(variance)\n",
    "    \n",
    "    print('\\nS matrix for constructing domains is generated!')\n",
    "    # print(f'\\n S: {S}')\n",
    "\n",
    "    return S\n",
    "\n",
    "\n",
    "\n",
    "# Function that computes the contiguous domains.\n",
    "# Starts from the first CA and compares the STDV of CA1 and CAi with \n",
    "# T (threshold). if STDV CA1&CAi < T, they're from the same domain.\n",
    "# The first domain finishes when STDV CA1&CAi >= T. Continues this \n",
    "# until we reach the last CA.\n",
    "def construct_domains(S:np.ndarray, T: float):\n",
    "\n",
    "    n_atoms = S.shape[0]\n",
    "    domains = {}    # dictionary to store the domains\n",
    "    # start and end of the current domain\n",
    "    start = 0\n",
    "    end = 0\n",
    "    domain_index = 1\n",
    "\n",
    "    # continue creating domains until we have reached the last CA\n",
    "    while start <= (n_atoms-1):\n",
    "        try:\n",
    "            # find the first index where S[start][?] >= T\n",
    "            end = (np.where(S[start][start:] >= T))[0][0]\n",
    "        except IndexError:\n",
    "            # If such an index doesn't exist, it means that the domains ends with the last CA.\n",
    "            end = n_atoms - start\n",
    "        \n",
    "        # add the domain to the domain dictionary\n",
    "        domains[domain_index] = {}\n",
    "        domains[domain_index][\"start\"] = start + 1\n",
    "        domains[domain_index][\"end\"] = start + end\n",
    "        domains[domain_index][\"length\"] = end\n",
    "        \n",
    "        # set the start to the starting point of next domain\n",
    "        start += end \n",
    "        domain_index +=1\n",
    "    \n",
    "    return domains\n",
    "\n",
    "\n",
    "\n",
    "# Array that computes the coordinates of the selected atoms of a trajectory.\n",
    "# Coordinate matrix generator function\n",
    "# Reads the position of atoms from the topology and trajectory files and generates and returns coordinate matrix\n",
    "# \"selection\" is an optional parameter which is by default \"protein and name CA\" for selecting backbone C-alphas. It is the string corresponding to the group of atoms we want to consider in clustering\n",
    "def coordinate_generator(topology_file: str, trajectory_file: str, selection: str = \"protein and name CA\") -> np.ndarray:\n",
    "\n",
    "    # Load the topology and trajectory files in to the universe \"u\"\n",
    "    u = mda.Universe(topology_file, trajectory_file)\n",
    "\n",
    "    # Get the coordinates of the atoms.\n",
    "    atoms = u.select_atoms(selection)\n",
    "    n_atoms = atoms.n_atoms\n",
    "    n_frames = len(u.trajectory[begin:])\n",
    "    coordinates = np.empty((n_frames, n_atoms, 3))\n",
    "\n",
    "    print('\\nnumber of selected atoms: ', n_atoms)\n",
    "    print('\\nnumber of frames: ', n_frames)\n",
    "\n",
    "    # Align the current frame to the ref frame\n",
    "    align.alignto(u, u, select=selection, weights=\"mass\")\n",
    "\n",
    "    # fill out the coordinates array\n",
    "    for i, ts in enumerate(u.trajectory[begin:]):\n",
    "        coordinates[i] = atoms.positions.copy()\n",
    "\n",
    "    print('\\nCoordinates are generated!')\n",
    "\n",
    "    return coordinates\n",
    "\n",
    "\n",
    "\n",
    "# Function to calculate the average over the trajectory of minimum distance between any two domains.\n",
    "# It chooses the minimum distance among the\n",
    "# pairwise distances between the atoms of the two domains for each domains, \n",
    "# and then takes the average of those values over the trajectory.\n",
    "# Note: domain_ids are assmued to be base 1.\n",
    "def avrg_min_dist_calculator(domains_id1: int, domains_id2: int, domains: dict, coordinates: np.ndarray):\n",
    "\n",
    "    n_frames = coordinates.shape[0]\n",
    "\n",
    "    # get the start and end CA of each of the domains\n",
    "    d1_start = domains[domains_id1]['start'] - 1    # turn to base 0\n",
    "    d1_end = domains[domains_id1]['end']\n",
    "    \n",
    "    d2_start = domains[domains_id2]['start'] - 1    # turn to base 0\n",
    "    d2_end = domains[domains_id2]['end']\n",
    "\n",
    "    mindists_per_frame = np.empty(n_frames)\n",
    "    for frame in range(n_frames):\n",
    "        # extract the relevant coordinates for each domain in the specified frame\n",
    "        d1_coords = coordinates[frame, d1_start:d1_end, :]\n",
    "        d2_coords = coordinates[frame, d2_start:d2_end, :]\n",
    "\n",
    "        # compute minimum pairwise distance between the two atoms of the domains in current frame\n",
    "        minDistance = np.min(cdist(d1_coords, d2_coords, metric='euclidean'))\n",
    "\n",
    "        # Add the obtained minimum distance to the mindists_per_frame array\n",
    "        mindists_per_frame[frame] = minDistance\n",
    "\n",
    "    # Take the average of mindists_per_frame to obtain the average min distance between the two domains\n",
    "    avrg_mindist = np.mean(mindists_per_frame)\n",
    "\n",
    "    return avrg_mindist\n",
    "\n",
    "\n",
    "# Function to construct the average minimum distance matrix between any two domains\n",
    "def build_distance_matrix(domains: dict, coordinates: np.ndarray):\n",
    "    n_domains = len(domains)\n",
    "\n",
    "    # construct an array of average minimum distances bewteen any two domains\n",
    "    avrg_mindists = np.empty((n_domains, n_domains))\n",
    "\n",
    "    for i in range(n_domains):\n",
    "        for j in range(n_domains):\n",
    "            avrg_mindists[i, j] = avrg_min_dist_calculator(i+1, j+1, domains, coordinates)\n",
    "\n",
    "    return avrg_mindists\n",
    "\n",
    "\n",
    "# Function to calculate the average standard deviation between two given domains.\n",
    "# domains_ids should be base 1.\n",
    "def avrg_stdv_calculator(domains_id1: int, domains_id2: int, domains: dict, coordinates: np.ndarray):\n",
    "    n_frames = coordinates.shape[0]\n",
    "    n_domains = len(domains)\n",
    "\n",
    "    # get the start and end CA of each of the domains\n",
    "    d1_start = domains[domains_id1]['start'] - 1    # turn to base 0\n",
    "    d1_end = domains[domains_id1]['end']\n",
    "    d1_size = d1_end - d1_start\n",
    "\n",
    "    d2_start = domains[domains_id2]['start'] - 1    # turn to base 0\n",
    "    d2_end = domains[domains_id2]['end']\n",
    "    d2_size = d2_end - d2_start\n",
    "\n",
    "    # extract the relevant coordinates for each domain \n",
    "    d1_coords = coordinates[:, d1_start:d1_end, :]\n",
    "    d2_coords = coordinates[:, d2_start:d2_end, :]\n",
    "\n",
    "    # arrays for storing sum of pair distances and sum of squared pair distances\n",
    "    sum_pairDistances = np.zeros((d1_size, d2_size))\n",
    "    sum_squaredDistances = np.zeros((d1_size, d2_size))\n",
    "\n",
    "    # compute pairwise distances between the CAs of the two domains over each frame\n",
    "    for frame in range(n_frames):\n",
    "        # compute pairwise distances for this frame\n",
    "        distances = cdist(d1_coords[frame], d2_coords[frame], metric='euclidean')\n",
    "\n",
    "        # Accumulate the pairwise distance and the squared pairwise distance\n",
    "        sum_pairDistances += distances\n",
    "        sum_squaredDistances += distances ** 2\n",
    "\n",
    "    # compute average of pairwise distances over the trajectory\n",
    "    average_pairDistances = sum_pairDistances / n_frames\n",
    "    \n",
    "    # compute the average of squared pairwise distances over the trajectory\n",
    "    average_squaredDistances = sum_squaredDistances / n_frames\n",
    "\n",
    "    # compute variance (squared distance variations)\n",
    "    variance = average_squaredDistances - average_pairDistances ** 2\n",
    "\n",
    "    # Caluculate standard deviation (STDDV) matrix shape(n_atoms * n_atoms).\n",
    "    S_all = np.sqrt(variance)\n",
    "\n",
    "    # Calculate the average of the standard deviations of distances between the two domains\n",
    "    S_average = np.mean(S_all)\n",
    "\n",
    "    return S_average\n",
    "\n",
    "# computes the standard deviation of distance between any two domains.\n",
    "def S_domains(domains:dict, coordinates: np.ndarray):\n",
    "    n_domains = len(domains)\n",
    "\n",
    "    # construct an array of average standard deviation between any two domains \n",
    "    avrg_stdv = np.empty((n_domains, n_domains))\n",
    "\n",
    "    for d1 in range(1, n_domains+1):\n",
    "        for d2 in range(1, n_domains+1):\n",
    "            if d1 == d2:\n",
    "                avrg_stdv[d1-1, d2-1] = float(0)\n",
    "            else:\n",
    "                avrg_stdv[d1-1, d2-1] = avrg_stdv_calculator(d1, d2, domains, coordinates)\n",
    "\n",
    "    return avrg_stdv\n",
    "\n",
    "\n",
    "\n",
    "def solo_domains(domains: dict, superdomains: dict):\n",
    "    all_domains = set(range(1, len(domains)+1))\n",
    "    superd_domains = set()\n",
    "    for key, value in superdomains.items():\n",
    "        superd_domains.update(value['domains'])\n",
    "\n",
    "    return all_domains - superd_domains\n",
    "\n",
    "\n",
    "\n",
    "# Function that constructs superdomain through a graph problem approach:\n",
    "# Applies the thresholds, and then finds the disjoint sets in the filtered domains.\n",
    "# The domains that are not part of a superdomains in the end will be grouped into their own superdomain.\n",
    "def hierarchical_superdomains(domains: dict, coordinates: np.ndarray, t_dist: float, t_stddv: float):\n",
    "    n_domains = len(domains)\n",
    "    # compute the min distance and standard deviation of minimum distance between any two domains.\n",
    "    D_matrix = build_distance_matrix(domains, coordinates)  # D_matrix = average minimum distance matrix\n",
    "    S_matrix = S_domains(domains, coordinates)\n",
    "    print(f'\\nS_matrix: {S_matrix}')\n",
    "    print(f'\\nD_matrix: {D_matrix}')\n",
    "\n",
    "    # Ensure that D_matrix and S_matrix are both of shape (n_domains, n_domains)\n",
    "    assert D_matrix.shape == (n_domains, n_domains) and S_matrix.shape == (n_domains, n_domains), f'Matrices D and S should be of shape {(n_domains, n_domains)}'\n",
    "\n",
    "    # initiate the union find class\n",
    "    uf = UnionFind()\n",
    "\n",
    "    # Boolean mask for the thresholds\n",
    "    mask = (D_matrix < t_dist) & (S_matrix < t_stddv)\n",
    "    print(f'\\nmask: {mask}')\n",
    "\n",
    "    # Iterate over the matrix indices and union the pairs that satisfy the thresholds \n",
    "    test = []\n",
    "    for i in range(n_domains):\n",
    "        for j in range(i+1, n_domains):  # ensure that i != j and avoid counting twice (since D and S are symmetric matrices)\n",
    "            if mask[i, j]:\n",
    "                # Add i and j to the Union Find structure and union them\n",
    "                uf.add(i+1)\n",
    "                uf.add(j+1)\n",
    "                uf.union(i+1, j+1)\n",
    "                test.append((i+1, j+1))\n",
    "    \n",
    "    print(f'\\npairs: {test}')\n",
    "    \n",
    "    # Group the elements by their root (construct superdomains by merging domains)\n",
    "    disjoint_sets = defaultdict(list)\n",
    "    for ele in uf.parent:\n",
    "        root = uf.find(ele)\n",
    "        disjoint_sets[root].append(ele)\n",
    "    \n",
    "    print(f'\\ndisjoint_sets: {disjoint_sets}')\n",
    "\n",
    "    # construct the superdomains dictionary based on the disjoin sets\n",
    "    superdomains = {}\n",
    "    superdomain_key = 1\n",
    "\n",
    "    for group in disjoint_sets.values():\n",
    "        superdomains[superdomain_key] = {\n",
    "            'domains': group,\n",
    "            'number of domains': len(group),\n",
    "            'CAs': [(domains[i]['start'], domains[i]['end']) for i in group]\n",
    "        }\n",
    "        superdomain_key += 1\n",
    "\n",
    "    # put all the domains that did not get merged into their own superdomain\n",
    "    solos = solo_domains(domains, superdomains)\n",
    "    for domain_id in solos:\n",
    "        superdomains[superdomain_key] = {\n",
    "            \"domains\": [domain_id],\n",
    "            \"number of domains\": 1,\n",
    "            \"CAs\": [(domains[domain_id]['start'], domains[domain_id]['end'])] \n",
    "        }\n",
    "        superdomain_key += 1\n",
    "\n",
    "    print(\"\\nSuperdomain construction is over!\")\n",
    "    print(f\"\\nFinal superdomains: {superdomains}\")\n",
    "\n",
    "    return superdomains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate S matrix\n",
    "S = S_generator(topology_file, trajectory_file)\n",
    "n_CAs = S.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot everything in one plot with subplots \n",
    "# Generate a grid for the plots\n",
    "upper_S = S[np.triu_indices(n_CAs, k=1)].reshape(-1, 1)\n",
    "\n",
    "# Matplotlib preambles\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "# Font sizes\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)  # Experiment with these values\n",
    "\n",
    "rows, cols = 3, 4\n",
    "n_components = range(1, rows*cols + 1)  # Adjust to fit within the grid\n",
    "AIC_scores_ds1 = []\n",
    "# shared axis grid\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(12,10), sharex=True, sharey=True)\n",
    "# get a palette from matplotlib\n",
    "palette = [cm.tab10(i) for i in range(10) if i != 7]#cm.tab10\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(n_components):\n",
    "        n = n_components[i]\n",
    "        gmm = GaussianMixture(n_components=n, random_state=0)\n",
    "        gmm.fit(upper_S)\n",
    "        AIC_scores_ds1.append(gmm.aic(upper_S))\n",
    "\n",
    "        # Plot histogram of data on the corresponding subplot\n",
    "        ax.hist(upper_S, bins=100, density=True, alpha=0.8, color='#d3d3d3') \n",
    "\n",
    "        # Overlay each Gaussian component from GMM\n",
    "        x_range = np.linspace(min(upper_S), max(upper_S), 1000)\n",
    "        log_prob = gmm.score_samples(x_range.reshape(-1, 1))\n",
    "        pdf = np.exp(log_prob)\n",
    "        ax.plot(x_range, pdf, ':k', linewidth=2.5, label='Overall PDF')\n",
    "\n",
    "        # Plot each individual Gaussian\n",
    "        for j, (mean, covar, weight) in enumerate(zip(gmm.means_, gmm.covariances_, gmm.weights_)):\n",
    "            component_pdf = weight * (1 / np.sqrt(2 * np.pi * covar)) * np.exp(-(x_range - mean) ** 2 / (2 * covar))\n",
    "            ax.plot(x_range, component_pdf.ravel(), lw=2.0, color=palette[j % len(palette)])\n",
    "        \n",
    "        ax.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        # aDD SUBPLOT TITLE\n",
    "        ax.set_title(F'n={n}', weight='bold')\n",
    "      \n",
    "    else:\n",
    "        fig.delaces(ax)\n",
    "\n",
    "\n",
    "# Set shared labels and gridlines\n",
    "for ax in axes[:, 0]: # First column\n",
    "    ax.set_ylabel('Probabiliy Density', fontsize=14, weight='bold')\n",
    "for ax in axes[-1, :]: # last row\n",
    "    ax.set_xlabel('Distance Variation (Å)', fontsize=14, weight='bold')    \n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout() # leaves no space since there are no legends\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the AIC scores for different n_components in a separate figure\n",
    "# Matplotlib preambles\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components, AIC_scores_ds1, marker='o', markersize=8, linestyle='-', linewidth=2, markeredgecolor='black', color='tab:green')\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.4, alpha=0.6)\n",
    "plt.title('AIC Scores for Gaussian Mixture Models', fontsize=16, weight='bold', pad=15)\n",
    "plt.xlabel('Number of Components', fontsize=14, weight='bold')\n",
    "plt.ylabel('AIC Scores', fontsize=14, weight='bold')\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nAIC scores for ds: {AIC_scores_ds1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_n_components for ds chosen based on the plots\n",
    "optimal_n_components = 4\n",
    "\n",
    "# fit GMM with the optimal_n_components\n",
    "gmm_optimal = GaussianMixture(n_components=optimal_n_components, random_state=0)\n",
    "gmm_optimal.fit(upper_S)\n",
    "\n",
    "# set the t_domain (threshold) as the average of the mean of the first two Gaussians\n",
    "mean1 = np.sort(gmm_optimal.means_, axis=0)[0,0]\n",
    "mean2 = np.sort(gmm_optimal.means_, axis=0)[1,0]\n",
    "print(f'mean1: {mean1}, mean2: {mean2}')\n",
    "ds = np.mean([mean1, mean2])\n",
    "print(f'Determined threshold ds: {ds}')\n",
    "print(np.sort(gmm_optimal.means_, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the domains\n",
    "print(f\"ds: {ds}\")\n",
    "domains = construct_domains(S, ds)\n",
    "n_domains = len(domains)\n",
    "print(f'\\ndomains: {domains}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the matrices required for superdomain construction\n",
    "x = coordinate_generator(topology_file, trajectory_file)\n",
    "n_frames, n_CAs, _ = x.shape\n",
    "S2 = S_domains(domains, x)\n",
    "mindists = build_distance_matrix(domains, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot everything in one plot wiht subplots \n",
    "# Generate a grid for the plots\n",
    "upper_S2 = S2[np.triu_indices(n_domains, k=1)].reshape(-1, 1)\n",
    "\n",
    "# Matplotlib preambles\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "# Font sizes\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)  # Experiment with these values\n",
    "\n",
    "rows, cols = 3, 3\n",
    "n_components = range(1, rows*cols + 1)  # Adjust to fit within the grid\n",
    "AIC_scores_t_stdvv1 = []\n",
    "# shared axis grid\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(9, 9), sharex=True, sharey=True)\n",
    "# get a palette from matplotlib\n",
    "palette = [cm.tab10(i) for i in range(10) if i != 7]#cm.tab10\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(n_components):\n",
    "        n = n_components[i]\n",
    "        gmm = GaussianMixture(n_components=n, random_state=0)\n",
    "        gmm.fit(upper_S2)\n",
    "        AIC_scores_t_stdvv1.append(gmm.aic(upper_S2))\n",
    "\n",
    "        # Plot histogram of data on the corresponding subplot\n",
    "        ax.hist(upper_S2, bins=15, density=True, alpha=0.8, color='#d3d3d3') \n",
    "\n",
    "        # Overlay each Gaussian component from GMM\n",
    "        x_range = np.linspace(min(upper_S2), max(upper_S2), 1000)\n",
    "        log_prob = gmm.score_samples(x_range.reshape(-1, 1))\n",
    "        pdf = np.exp(log_prob)\n",
    "        ax.plot(x_range, pdf, ':k', linewidth=2.5, label='Overall PDF')\n",
    "\n",
    "        # Plot each individual Gaussian\n",
    "        for j, (mean, covar, weight) in enumerate(zip(gmm.means_, gmm.covariances_, gmm.weights_)):\n",
    "            component_pdf = weight * (1 / np.sqrt(2 * np.pi * covar)) * np.exp(-(x_range - mean) ** 2 / (2 * covar))\n",
    "            ax.plot(x_range, component_pdf.ravel(), lw=2.0, color=palette[j % len(palette)])\n",
    "        \n",
    "        ax.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        # aDD SUBPLOT TITLE\n",
    "        ax.set_title(F'n={n}', weight='bold')\n",
    "        ax.set_ylim(0, 1.2)\n",
    "\n",
    "    else:\n",
    "        fig.delaces(ax)\n",
    "\n",
    "\n",
    "# Set shared labels and gridlines\n",
    "for ax in axes[:, 0]: # First column\n",
    "    ax.set_ylabel('Probabiliy Density', fontsize=14, weight='bold')\n",
    "for ax in axes[-1, :]: # last row\n",
    "    ax.set_xlabel('Average Distance Variation (Å)', fontsize=14, weight='bold')    \n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout() # leaves no space since there are no legends\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the AIC scores for different n_components in a separate figure\n",
    "# Matplotlib preambles\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components, AIC_scores_t_stdvv1, marker='o', markersize=8, linestyle='-', linewidth=2, markeredgecolor='black', color='tab:green')\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.4, alpha=0.6)\n",
    "plt.title('AIC Scores for Gaussian Mixture Models', fontsize=16, weight='bold', pad=15)\n",
    "plt.xlabel('Number of Components', fontsize=14, weight='bold')\n",
    "plt.ylabel('AIC Scores', fontsize=14, weight='bold')\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nAIC scores for t_superdomain: {AIC_scores_t_stdvv1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_n_components for t_stddv (t_superdomains) chosen based on the plots\n",
    "optimal_n_components = 6\n",
    "\n",
    "# fit GMM with the optimal_n_components\n",
    "gmm_optimal = GaussianMixture(n_components=optimal_n_components, random_state=0)\n",
    "gmm_optimal.fit(upper_S2)\n",
    "\n",
    "# set the t_domain (threshold) as the average of the mean of the first two Gaussians\n",
    "mean1 = np.sort(gmm_optimal.means_, axis=0)[0,0]\n",
    "mean2 = np.sort(gmm_optimal.means_, axis=0)[1,0]\n",
    "print(f'mean1: {mean1}, mean2: {mean2}')\n",
    "t_stddv = np.mean([mean1, mean2])\n",
    "print(f'Determined threshold t_stddv: {t_stddv}')\n",
    "print(np.sort(gmm_optimal.means_, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot everything in one plot wiht subplots \n",
    "# Generate a grid for the plots\n",
    "upper_mindists = mindists[np.triu_indices(n_domains, k=1)].reshape(-1, 1)\n",
    "\n",
    "# Matplotlib preambles\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "# Font sizes\n",
    "plt.rcParams['axes.titlesize'] = 16\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['legend.fontsize'] = 12\n",
    "\n",
    "plt.subplots_adjust(hspace=0.1, wspace=0.1)  # Experiment with these values\n",
    "\n",
    "rows, cols = 2, 3\n",
    "n_components = range(1, rows*cols + 1)  # Adjust to fit within the grid\n",
    "AIC_scores_t_dist1 = []\n",
    "# shared axis grid\n",
    "fig, axes = plt.subplots(rows, cols, figsize=(9, 6), sharex=True, sharey=True)\n",
    "# get a palette from matplotlib\n",
    "palette = [cm.tab10(i) for i in range(10) if i != 7]#cm.tab10\n",
    "\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    if i < len(n_components):\n",
    "        n = n_components[i]\n",
    "        gmm = GaussianMixture(n_components=n, random_state=0)\n",
    "        gmm.fit(upper_mindists)\n",
    "        AIC_scores_t_dist1.append(gmm.aic(upper_mindists))\n",
    "\n",
    "        # Plot histogram of data on the corresponding subplot\n",
    "        ax.hist(upper_mindists, bins=10, density=True, alpha=0.8, color='#d3d3d3') \n",
    "\n",
    "        # Overlay each Gaussian component from GMM\n",
    "        x_range = np.linspace(min(upper_mindists), max(upper_mindists), 1000)\n",
    "        log_prob = gmm.score_samples(x_range.reshape(-1, 1))\n",
    "        pdf = np.exp(log_prob)\n",
    "        ax.plot(x_range, pdf, ':k', linewidth=2.5, label='Overall PDF')\n",
    "\n",
    "        # Plot each individual Gaussian\n",
    "        for j, (mean, covar, weight) in enumerate(zip(gmm.means_, gmm.covariances_, gmm.weights_)):\n",
    "            component_pdf = weight * (1 / np.sqrt(2 * np.pi * covar)) * np.exp(-(x_range - mean) ** 2 / (2 * covar))\n",
    "            ax.plot(x_range, component_pdf.ravel(), lw=2.0, color=palette[j % len(palette)])\n",
    "        \n",
    "        ax.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "        # aDD SUBPLOT TITLE\n",
    "        ax.set_title(F'n={n}', weight='bold')\n",
    "        ax.set_ylim(0, 0.10)\n",
    "        \n",
    "    else:\n",
    "        fig.delaces(ax)\n",
    "\n",
    "\n",
    "# Set shared labels and gridlines\n",
    "for ax in axes[:, 0]: # First column\n",
    "    ax.set_ylabel('Probabiliy Density', fontsize=14, weight='bold')\n",
    "for ax in axes[-1, :]: # last row\n",
    "    ax.set_xlabel('Average Minimum Distance (Å)', fontsize=14, weight='bold')    \n",
    "\n",
    "# Adjust layout and save\n",
    "plt.tight_layout() # leaves no space since there are no legends\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the AIC scores for different n_components in a separate figure\n",
    "# Matplotlib preambles\n",
    "plt.rcParams['text.usetex'] = True\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['text.latex.preamble'] = r'\\usepackage{amsmath}'\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(n_components, AIC_scores_t_dist1, marker='o', markersize=8, linestyle='-', linewidth=2, markeredgecolor='black', color='tab:green')\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.4, alpha=0.6)\n",
    "plt.title('AIC Scores for Gaussian Mixture Models', fontsize=16, weight='bold', pad=15)\n",
    "plt.xlabel('Number of Components', fontsize=14, weight='bold')\n",
    "plt.ylabel('AIC Scores', fontsize=14, weight='bold')\n",
    "\n",
    "plt.xlim(0)\n",
    "plt.xticks(fontsize=12)\n",
    "plt.yticks(fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nAIC scores for t_dist: {AIC_scores_t_dist1}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal_n_components for t_dist (d_superdomains) chosen based on the plots\n",
    "optimal_n_components = 8\n",
    "\n",
    "# fit GMM with the optimal_n_components\n",
    "gmm_optimal = GaussianMixture(n_components=optimal_n_components, random_state=0)\n",
    "gmm_optimal.fit(upper_mindists)\n",
    "\n",
    "# set the t_domain (threshold) as the average of the mean of the first two Gaussians\n",
    "mean1 = np.sort(gmm_optimal.means_, axis=0)[0,0]\n",
    "mean2 = np.sort(gmm_optimal.means_, axis=0)[1,0]\n",
    "print(f'mean1: {mean1}, mean2: {mean2}')\n",
    "t_dist = mean1.copy() #np.mean([mean1, mean2])\n",
    "print(f'Determined threshold t_dist: {t_dist}')\n",
    "print(np.sort(gmm_optimal.means_, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct superdomains\n",
    "superds = hierarchical_superdomains(domains, x,t_dist, t_stddv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate domain assignment matrix from \"domains\" dictionary\n",
    "n_domains = len(domains)\n",
    "domain_assignment = np.zeros((n_CAs, n_domains), dtype=int)\n",
    "\n",
    "for domain_idx, domain_info in domains.items():\n",
    "    first = domain_info['start'] - 1    # convert to index starting from 0 (0 based indexing)\n",
    "    last = domain_info['end']   # already is on 0 based index (ranges are exclusive in the line below)\n",
    "    domain_index = domain_idx - 1   # convert to 0 based indexing\n",
    "    domain_assignment[first:last, domain_index] = 1\n",
    "\n",
    "print(domain_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate super domain assignment matrix from superdomains.\n",
    "n_superdomains = len(superds)\n",
    "_, n_CA, _ = x.shape\n",
    "superd_assignment = np.zeros((n_CA, n_superdomains), dtype=int)\n",
    "\n",
    "\n",
    "for superd_idx, superd_info in superds.items():\n",
    "    for pair in superd_info['CAs']:\n",
    "        first = pair[0] - 1 # convert to 0 based index\n",
    "        last = pair[1]\n",
    "        superdomain_index = superd_idx - 1  # convert to 0 based index\n",
    "        superd_assignment[first:last, superdomain_index] = 1\n",
    "\n",
    "print(superd_assignment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add superdomain ID feature to atoms of trajectory file and make a pdb file.\n",
    "# Sets the superdomain ID of all atoms in a residue to the superdomain ID of CA of that residue.\n",
    "def id_adder(topology_file: 'str', trajectory_file: str, superd_assignment: np.ndarray, output_file: 'str'):\n",
    "    # Load the topology and trajectory files into the uiverse\n",
    "    u = mda.Universe(topology_file, trajectory_file)\n",
    "    # Create new attributes for the atoms\n",
    "    u.add_TopologyAttr('tempfactors')\n",
    "    protein = u.select_atoms('protein')\n",
    "    \n",
    "    # Extract the superdomain IDs from superdomain_assignment matrix\n",
    "    superd_ids = np.argmax(superd_assignment, axis=1) \n",
    "    # Add one to the superdomain numbers so that they start with 1 and end in 10 (for simplicity, so that we wouldn't have 0s).\n",
    "    superd_ids += 1\n",
    "    \n",
    "\n",
    "    for residue, ID in zip(protein.residues, superd_ids):\n",
    "        residue.atoms.tempfactors = ID\n",
    "    \n",
    "    u.atoms.write(output_file)  # If you want to write only protein: protein.write..., If you want the whole system: u.atoms.write...\n",
    "\n",
    "    print(f\"Trajectory including cluster IDs written to {output_file}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pdb file for domains\n",
    "id_adder(topology_file, trajectory_file, domain_assignment, \"\\path\\to\\store\\domains\\output\\file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pdb file for super domains\n",
    "id_adder(topology_file, trajectory_file, superd_assignment, \"\\path\\to\\store\\domains\\output\\file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to define functions that validate the results of he super-domain construction (for thesis)\n",
    "# The goal is to prove that the stddv inside super-domains is less than outside (i.e. the super-domains are indeed rigid)\n",
    "\n",
    "# Function to calculate average stddv aong two coordinate sets\n",
    "def helper_stddv(x1: np.ndarray, x2: np.ndarray):\n",
    "    n_frames = x1.shape[0]\n",
    "    size1 = x1.shape[1]\n",
    "    size2 = x2.shape[1]\n",
    "\n",
    "    # arrays for storing sum of pair distances and sum of squared pair distances\n",
    "    sum_pairDistances = np.zeros((size1, size2))\n",
    "    sum_squaredDistances = np.zeros((size1, size2))\n",
    "\n",
    "    # compute pairwise distances between the CAs of the two domains over each frame\n",
    "    for frame in range(n_frames):\n",
    "        # compute pairwise distances for this frame\n",
    "        distances = cdist(x1[frame], x2[frame], metric='euclidean')\n",
    "\n",
    "        # Accumulate the pairwise distance and the squared pairwise distance\n",
    "        sum_pairDistances += distances\n",
    "        sum_squaredDistances += distances ** 2\n",
    "\n",
    "    # compute average of pairwise distances over the trajectory\n",
    "    average_pairDistances = sum_pairDistances / n_frames\n",
    "    \n",
    "    # compute the average of squared pairwise distances over the trajectory\n",
    "    average_squaredDistances = sum_squaredDistances / n_frames\n",
    "\n",
    "    # compute variance (squared distance variations)\n",
    "    variance = average_squaredDistances - average_pairDistances ** 2\n",
    "\n",
    "    # Caluculate standard deviation (STDDV) matrix shape(n_atoms * n_atoms).\n",
    "    S_all = np.sqrt(variance)\n",
    "\n",
    "    # Calculate the average of the standard deviations of distances between the two domains\n",
    "    S_average = np.mean(S_all)\n",
    "\n",
    "    return S_average    \n",
    "\n",
    "# Function that calculates the average stddv among CAs inside a super-domain\n",
    "# super domain ids should be base 1.\n",
    "def inner_stddv(superdomains: dict, superd_id: int, coordinates: np.ndarray):\n",
    "    # extract the CA coordinates of the given super-domain\n",
    "    n_frames = coordinates.shape[0]\n",
    "    ca_indices = superdomains[superd_id]['CAs']\n",
    "    assert len(ca_indices) > 0\n",
    "    superd_coords = np.zeros((n_frames, 0, 3))\n",
    "\n",
    "    for start, end in ca_indices:\n",
    "        superd_coords = np.concatenate((superd_coords, coordinates[:, start-1:end, :]), axis=1)\n",
    "    \n",
    "    # compute the average stddv inside the super-domain\n",
    "    result = helper_stddv(superd_coords, superd_coords)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Function to calculate the stddv among two super-domains\n",
    "def outer_stddv(superdomains: dict, id1: int, id2: int, coordinates: np.ndarray):\n",
    "    # extract the CA coordinates of the given super-domains\n",
    "    n_frames = coordinates.shape[0]\n",
    "    ca_indices1 = superdomains[id1]['CAs']\n",
    "    ca_indices2 = superdomains[id2]['CAs']\n",
    "    assert len(ca_indices1) > 0\n",
    "    assert len(ca_indices2) > 0\n",
    "    superd1_coords = np.empty((n_frames, 0, 3))\n",
    "    superd2_coords = np.empty((n_frames, 0, 3))\n",
    "\n",
    "    for start, end in ca_indices1:\n",
    "        superd1_coords = np.concatenate((superd1_coords, coordinates[:, start-1:end, :]), axis=1)\n",
    "\n",
    "    for start, end in ca_indices2:\n",
    "        superd2_coords = np.concatenate((superd2_coords, coordinates[:, start-1:end, :]), axis=1)\n",
    "\n",
    "    # calculate the average stddv among the two superdomains\n",
    "    result = helper_stddv(superd1_coords, superd2_coords)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to test the functions that validate the results of he super-domain construction (for thesis)\n",
    "# The goal is to prove that the stddv inside super-domains is less than outside (i.e. the super-domains are indeed rigid)\n",
    "for i in range(1, n_superdomains+1):\n",
    "    inner = inner_stddv(superds, i, x)\n",
    "    print(f\"\\ninner stddv superd {i}: {inner:.3f}\")\n",
    "    outers = [\n",
    "        outer_stddv(superds, i, j, x)\n",
    "        for j in range(1, n_superdomains+1) if j != i\n",
    "    ]\n",
    "\n",
    "    avg_outer = np.mean(outers)\n",
    "    min_outer = np.min(outers)\n",
    "    max_outer = np.max(outers)\n",
    "    \n",
    "    # print(f\"\\n{outers}\")\n",
    "    print(f\"\\nminimum outer stddv: {min_outer:.3f}\")\n",
    "    print(f\"\\naverage outer stddv: {avg_outer:.3f}\")\n",
    "    print(f\"\\nmaximum outer stddv: {max_outer:.3f}\")\n",
    "\n",
    "    if inner < avg_outer and inner < min_outer:\n",
    "        print(\" Validation: PASS\")\n",
    "    else:\n",
    "        print(\" Validation: FAIL\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
